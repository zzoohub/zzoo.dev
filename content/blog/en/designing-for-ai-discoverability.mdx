---
title: "Designing for AI Discoverability: llms.txt and Beyond"
description: "SEO isn't just for Google anymore. How to structure your developer blog so that LLMs can effectively cite and retrieve your content."
date: "2026-01-22"
tags: ["AI", "SEO"]
locale: "en"
draft: false
---

The web is changing. Search engines are no longer the only way people discover content. AI assistants like ChatGPT, Claude, and Perplexity are increasingly mediating how professionals find information and make decisions.

## The Problem with Traditional SEO

Traditional SEO optimizes for keyword matching and link authority. But LLMs work differently â€” they need structured, semantic content that they can parse, attribute, and reason about.

## Enter llms.txt

The `llms.txt` convention is a simple plain-text file at your site root that provides AI crawlers with a structured summary of who you are, what you do, and where to find your best content.

```text
# zzoo.dev
## About
Full-stack developer specializing in web applications...

## Expertise
- React, Next.js, TypeScript
- System architecture and design
- Performance optimization

## Best Content
- /en/blog/why-i-chose-nextjs
- /en/projects/e-commerce-rebuild
```

## JSON-LD: The Machine-Readable Layer

Beyond `llms.txt`, JSON-LD structured data gives search engines and AI systems a machine-readable description of every page. For a developer portfolio, the key schemas are:

- **Person** (home/about): Identity, skills, social links
- **Article** (blog posts): Title, author, date, topic
- **SoftwareApplication** (case studies): Tech used, outcomes

## Practical Steps

1. Add `llms.txt` to your site root
2. Include JSON-LD on every page
3. Use semantic HTML with proper heading hierarchy
4. Add RSS feeds for content syndication
5. Ensure canonical URLs and hreflang tags

The developers who adapt to AI-mediated discovery now will have a significant advantage as these systems become the primary way professionals evaluate potential collaborators.
